// Copyright (c) 2025 Pratik Barhate
// Licensed under the MIT License. See the LICENSE file in the project root for more information.

use std::io::Cursor;
use tract_onnx::{prelude::*, tract_hir::infer::Factoid};

use crate::inference::TractRunnableModel;

/// Loads an ONNX model from a byte vector into a Tract model for inference.
///
/// 1. Load the model from the byte array
/// 2. Determine input and output dimensions
/// 3. Analyze and optimize the model
/// 4. Build a runnable model
///
/// # Arguments
///
/// * `model_bytes` - A slice of bytes containing the ONNX model data
///
/// # Returns
///
/// Returns a Result containing:
/// - The optimized model ready for inference
/// - The input tensor length
/// Or an error
pub fn load_onnx_model(
    model_bytes: &[u8],
) -> Result<(TractRunnableModel, usize), Box<dyn std::error::Error>> {
    let model = tract_onnx::onnx()
        .model_for_read(&mut Cursor::new(model_bytes))
        .map_err(|e| Box::<dyn std::error::Error>::from(e))?;

    let input_fact = model.input_fact(0)?;
    // let output_fact = model.output_fact(0)?;

    let input_dims = input_fact.shape.dims().nth(1);
    // let output_dims = output_fact.shape.dims().nth(1);

    let input_length = match input_dims {
        Some(dim_fact) => match dim_fact.concretize() {
            Some(TDim::Val(val)) => val as usize,
            _ => return Err("Input shape factoid failed".into()),
        },
        None => return Err("Input shape has no dimensions".into()),
    };

    // There seems to be a bug for reading the output dimensions.
    // Probably it is a bug in the tract code
    // let output_length = match output_dims {
    //     Some(dim_fact) => match dim_fact.concretize() {
    //         Some(TDim::Val(val)) => val as usize,
    //         _ => return Err("Output shape factoid failed".into()),
    //     },
    //     None => return Err("Output shape has no dimensions".into()),
    // };

    let model = model
        .into_typed()
        .map_err(|e| Box::<dyn std::error::Error>::from(e))?;
    let model = model
        .into_optimized()
        .map_err(|e| Box::<dyn std::error::Error>::from(e))?;

    let model = model
        .into_runnable()
        .map_err(|e| Box::<dyn std::error::Error>::from(e))?;

    Ok((model, input_length))
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Read;
    use std::path::Path;

    #[test]
    fn test_single_inference() -> Result<(), Box<dyn std::error::Error>> {
        // Path to the model file that should be generated by the separate Python script
        let model_path = Path::new("test-data/sigmoid_model_3.onnx");

        // Skip the test if the model file doesn't exist
        if !model_path.exists() {
            eprintln!("Test model file not found at: {}", model_path.display());
            eprintln!("Please run the separate Python script to generate the test model.");
            assert!(false);
        }

        // Read the model bytes from the file
        let mut file = File::open(model_path)?;
        let mut model_bytes = Vec::new();
        file.read_to_end(&mut model_bytes)?;

        // Test loading the model from bytes and get dimensions
        let (model, input_length) = load_onnx_model(&model_bytes)?;

        // Check the dimensions
        assert_eq!(input_length, 3, "Expected input length of 3");

        // Create a single input: [1.0, 2.0, 3.0]
        let input = tract_ndarray::arr1(&[1.0f32, 2.0f32, 3.0f32])
            .into_shape_with_order((1, 3)) // Add batch dimension (batch size = 1)
            .unwrap()
            .into_arc_tensor();

        // Convert Arc<Tensor> to TValue for the model.run method
        let input = TValue::Const(input);

        // Run the model
        let outputs = model.run(tvec!(input))?;

        let output = outputs[0].to_array_view::<f32>()?;

        // Check they're within sigmoid range (0 to 1)
        assert!(output[[0, 0]] > 0.0f32 && output[[0, 0]] < 1.0f32);
        assert!(output[[0, 1]] > 0.0f32 && output[[0, 1]] < 1.0f32);

        Ok(())
    }

    #[test]
    fn test_batch_inference() -> Result<(), Box<dyn std::error::Error>> {
        // Path to the model file that should be generated by the separate Python script
        let model_path = Path::new("test-data/sigmoid_model_3.onnx");

        // Skip the test if the model file doesn't exist
        if !model_path.exists() {
            eprintln!("Test model file not found at: {}", model_path.display());
            eprintln!("Please run the separate Python script to generate the test model.");
            assert!(false);
        }

        // Read the model bytes from the file
        let mut file = File::open(model_path)?;
        let mut model_bytes = Vec::new();
        file.read_to_end(&mut model_bytes)?;

        // Load the model and get dimensions
        let (model, input_length) = load_onnx_model(&model_bytes)?;

        // Check the dimensions
        assert_eq!(input_length, 3, "Expected input length of 3");

        // Create a batch of inputs (3 samples, each with 3 features)
        let batch_input = tract_ndarray::arr2(&[
            [1.0f32, 2.0f32, 3.0f32], // Sample 1
            [0.5f32, 1.0f32, 1.5f32], // Sample 2
            [0.1f32, 0.2f32, 0.3f32], // Sample 3
        ])
        .into_arc_tensor();

        // Convert Arc<Tensor> to TValue for the model.run method
        let batch_input = TValue::Const(batch_input);

        // Run the model with batch input
        let outputs = model.run(tvec!(batch_input))?;

        // Check the output shape - should be [3, 2] (3 samples, each with 2 outputs)
        let output = outputs[0].to_array_view::<f32>()?;
        assert_eq!(output.shape(), &[3, 2]);

        // Check that all values are within sigmoid range (0 to 1)
        for batch_idx in 0..3 {
            for feature_idx in 0..2 {
                assert!(
                    output[[batch_idx, feature_idx]] >= 0.0f32
                        && output[[batch_idx, feature_idx]] <= 1.0f32
                );
            }
        }

        Ok(())
    }

    #[test]
    fn test_load_invalid_model() {
        // Test with invalid model bytes
        let invalid_bytes = vec![0, 1, 2, 3];
        let result = load_onnx_model(&invalid_bytes);

        // This should fail
        assert!(result.is_err());
    }
}
